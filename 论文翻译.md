## 论文翻译

## FedRecAttack：对联合推荐的模型中毒攻击

### 摘要:

联合推荐（FR）在过去几年中受到了相当大的欢迎和关注。在FR中，对于每个用户，其特征向量和交互数据都保存在其自己的客户端本地，因此对其他人来说是私有的。如果无法访问上述信息，大多数现有的针对推荐系统或联合学习的中毒攻击就会失去有效性。得益于这一特性，FR通常被认为是相当安全的。

然而，我们认为FR中仍然可以进行可能且必要的安全改进。为了证明我们的观点，在本文中，我们提出了FedRecAttack，这是一种针对FR的中毒攻击模型，旨在提高目标项目的暴露率。在大多数推荐场景中，除了私人的用户-项目交互（例如，点击、观看和购买）之外，一些交互是公开的（例如，喜欢、关注和评论）。

受此启发，在FedRecAttack中，我们利用公共交互来近似用户的特征向量，从而攻击者可以相应地生成中毒梯度，并控制恶意用户以精心设计的方式上传中毒梯度。为了评估FedRecAttack的有效性和副作用，我们对来自两个完全不同场景的三个不同大小的现实数据集进行了广泛的实验。

实验结果表明，我们提出的FedRecAttack达到了最先进的效果，而其副作用可以忽略不计。此外，即使在所有比例（3%）的恶意用户和所有比例（1%）的公共互动中，FedRecAttack仍然非常有效，这表明FR比人们通常认为的更容易受到攻击。

### 引言:

过去几年，推荐系统领域的研究主要集中在提高推荐准确度方面。具体来说，这些研究可大致分为三类。第一类是构建更复杂的推荐模型结构，例如NCF、NAIS、NGCF和LightGCN。第二类是集成更多辅助信息，如VBPR、CKE、MMGCN和KGIN。第三类是使推荐模型适应更具体领域的场景，比如电子商务、新闻和微视频。值得注意的是，当前的研究趋势是结合知识图谱来提高模型的表达能力。

然而，随着推荐系统在不同场景中广泛应用，研究人员开始关注推荐系统的安全性问题。推荐系统在人们的思维、判断和获取信息的方式中扮演着重要角色，因此安全问题涉及每个人。攻击者一旦获得推荐系统的控制权，就能操纵推荐结果，甚至影响社交媒体上的舆论，改变公众对特定热点事件的看法或态度，进而导致人们实际行为的改变。剑桥分析公司就是一家利用数据分析操纵政治舆论的典型例子。他们捕获不同社交媒体上用户与商品的交互，并利用这些数据生成用户档案，从而精准地向特定用户推荐广告，直接影响美国总统选举结果。

已有的攻击研究针对基于矩阵分解、深度学习和图的推荐系统进行数据中毒攻击。这些攻击高度依赖攻击者对用户-项目交互的先验知识，以近似推荐模型的参数，从而控制恶意用户产生虚假交互，提高目标项目的曝光率。与此同时，人们对隐私保护的关注也日益增加。在传统的集中式推荐系统中，服务器存储着所有历史用户-项目交互以及数百万用户的私人档案，包含大量敏感信息。一旦服务器数据泄露，将给数百万用户、企业和社会带来极其严重的负面影响。Facebook的数据泄露事件就是一个明显例子。欧盟颁布的《通用数据保护条例》（GDPR）以及其他国家的类似法规都旨在保护用户隐私。

联合推荐（FR）被认为是一种在保护用户隐私的前提下推荐项目的解决方案。在FR中，推荐系统在联合场景下接受训练，每个用户的交互数据和特征向量保存在本地客户端，对其他人（包括中央服务器）来说是私有的，从而防止攻击者访问用户的交互数据。由于攻击者无法获取用户的交互数据，现有的数据中毒攻击在FR中失去了效力。同样，针对联邦学习的模型中毒攻击也不适用于FR，因为它们需要完全访问模型参数，而每个用户的特征向量在FR中也是私有的。因此，FR被认为相当安全，攻击联合推荐系统成为一项极具挑战性的任务。

尽管如此，我们认为FR的安全性仍有改进的可能和必要。在众多社交平台上，除了私人互动外，还存在许多公开的互动，如点赞、关注和评论。虽然公共交互比例通常较高，但结合FR中共享模型参数的帮助，这些公开互动仍可能对攻击产生重大影响。因此，我们提出了FedRecAttack。在FedRecAttack中，攻击者通过公共交互和共享参数来近似用户的特征矩阵，并设计巧妙的方法生成中毒梯度，然后控制恶意用户以精心设计的方式上传这些中毒梯度。我们面临的主要挑战包括：1）仅对公共互动进行攻击，因为FR中的攻击者无法访问用户的交互数据，公共互动比例较低，现有攻击方法并不适用；2）在无法访问用户特征矩阵的情况下进行攻击，因为现有联邦学习的模型中毒攻击需要完全访问模型参数，而用户特征矩阵在FR中是私有的；3）进行隐秘攻击，确保在攻击的同时不产生明显的副作用。我们的研究工作旨在探索攻击联合推荐系统的可能性。我们设计了一种巧妙的方法来近似用户的特征矩阵，并利用它来计算中毒梯度。此外，我们还设计了一种复杂的方法，在某些限制下上传中毒梯度。我们的攻击可以有效地毒害推荐模型，同时副作用极小，几乎难以被检测到。我们的研究工作的主要贡献如下：

1. 我们提出了FedRecAttack，这是第一个针对FR的开源模型中毒攻击方法。
2. 通过来自两个完全不同场景的三个不同大小的现实数据集的评估，我们的FedRecAttack在所有基准攻击中达到了最高的有效性。与现有的数据中毒和模型中毒攻击相比，当恶意用户比例为全部时，FedRecAttack表现出了新的最先进水平。
3. 我们探讨了FedRecAttack的副作用。实验结果显示，FedRecAttack的副作用是所有模型中毒攻击中最轻微的，几乎无法被检测到。

总的来说，我们的工作揭示了联合推荐系统的脆弱性，并提出了一种有效且隐秘的攻击方法。然而，我们也认识到FR的安全性仍有改进的空间，需要进一步的研究来加强联合推荐系统的安全性。

### 相关工作:

推荐系统协作过滤推荐系统使用用户-项目交互（例如点击或喜好）来建模用户和项目的潜在特征。使用历史用户-项目交互来训练和优化推荐模型，使推荐系统能够预测未交互的用户-项目对之间的评分，描述用户喜欢该项目的程度。先前关于推荐系统（RS）的研究可以分为三类：

i) 基于矩阵分解的RS[32]-[35]，它简单地将用户和项目的特征向量的点积作为用户和项目之间的预测评分。

ii）基于深度学习的RS[1]，[36]-[40]，它使用深度学习模型来预测具有高度非线性的评分分数。

iii) 基于图的RS [3]、[4]，它将用户-项目交互视为二分图中的边，并尝试通过执行嵌入传播来利用高阶连接性。所有这些研究都设计了复杂的模型结构并提高了推荐性能。

针对推荐系统的攻击随着技术的成熟，推荐系统在不同场景中的应用不断广泛，关注推荐系统安全问题的研究人员也越来越多。现有的研究表明，当前的推荐系统在某些情况下是脆弱的，研究人员提出了许多针对推荐系统的有效攻击方法。其中一种攻击旨在导致推荐准确性的损失并破坏目标模型的有效性。另一种攻击的目的是向尽可能多的用户推荐特定的项目。在本文中，我们重点关注后者的攻击，因为它们更加隐蔽且危害更大。数据中毒攻击是攻击的主要形式，通过注入假用户并控制他们与一些谨慎的用户进行交互来进行攻击选择的项目，导致训练数据中毒。在中毒数据上训练的推荐模型将为许多用户预测目标项目的异常高评分。参考文献[15]-[17]、[41]提出了针对上述三类推荐系统的数据中毒攻击。然而，所有这些攻击的效果都有限，并且高度依赖攻击者的先验知识（即历史交互）。更具体地说，在[15]、[17]中，假设攻击者有权访问完整的交互，而在[16]、[41]中，假设攻击者有权访问部分交互（超过20%）。这些假设在现实场景中通常不切实际。

联合推荐联合推荐（FR）被认为不会受到此类攻击。图1展示了传统集中推荐和FR架构的区别。在FR中，对于每个用户，其交互数据都保存在其自己的客户端本地。如上所述，攻击者对历史交互的先验知识对于攻击至关重要，这意味着所有这些攻击在FR中都是无效的。由于FR具有保护用户隐私、免受攻击等优点，已成为研究热点。随着[21]提出第一个带有隐式反馈的FR框架，后续的研究如雨后春笋般涌现。在[22]中，通过随机采样用户未交互的项目来弥补显式反馈在FR中不适用的缺陷。基于[22]，[23]提出了一种无损联合推荐系统，该系统使用去噪客户端收集来自普通客户端的带有噪声的梯度。文献[24]将图神经网络应用于FR，在不失去对用户隐私保护的情况下取得了相当好的推荐精度。

针对联邦学习的攻击自联邦学习（FL）出现以来，FL的安全问题一直受到研究人员的关注，并提出了大量针对FL的攻击。模型中毒攻击是此类攻击的主要形式，其通过控制恶意用户上传中毒梯度来进行。参考文献[28]-[30]提出了分类任务中针对FL的模型中毒攻击。FR是FL的特例。然而，现有针对FL的攻击在FR中无效，原因如下：

i）大多数现有攻击都是在分类任务中设计的，但在FR中的学习目标与分类任务中的学习目标完全不同。

ii）现有的攻击依赖于攻击者对模型参数的完全访问，但在FR中，每个用户的特征向量对其他人都是隐藏的。

针对联合推荐的攻击针对FR的攻击方法仍处于探索之中。参考文献[31]提出了PipAttack，这是第一个针对FR的模型中毒攻击框架。其实验结果表明PipAttack在FR中是有效的。然而，PipAttack 有两个缺点：

i) PipAttack 会导致推荐准确率显着下降，从而增加被检测到的概率。

ii) PipAttack 需要很大比例（10%）的恶意用户才能实现其有效性，从而将攻击成本提高到相当难以承受的程度。

尽管上述两个特征都意味着目前的联邦推荐系统仍然很难造成严重损害，但我们认为FR的安全性仍然有必要改进。为了证明可以在FR中以可忽略的副作用和所有比例的恶意用户进行攻击，我们提出了FedRecAttack。

### 结论和未来工作:

在本文中，我们引入了一种名为FedRecAttack的针对联合推荐系统（FR）的模型中毒攻击。该攻击的目的是将目标项目推荐给尽可能多的用户，从而导致推荐准确性的损失并破坏目标模型的有效性。我们对FedRecAttack在三个不同大小的现实数据集上进行了评估，并获得了以下重要的实验结果：

**i) FedRecAttack达到了state-of-the-art的效果：** 在与现有的模型中毒攻击方法进行对比时，我们的FedRecAttack表现出了最高的有效性。通过利用公共交互和共享参数，我们的攻击能够近似用户的特征矩阵并生成中毒梯度，从而有效地影响推荐模型。

**ii) FedRecAttack在现有模型中毒攻击中副作用最小：** 我们的实验结果显示，与其他模型中毒攻击相比，FedRecAttack产生的副作用最轻微，几乎难以被检测到。这使得攻击更加隐蔽，加大了检测和防御的难度。

**iii) 当恶意用户比例和公共交互比例均为时，FedRecAttack 仍然表现良好：** 即使只有少数恶意用户参与攻击，并且公共交互比例较低，我们的FedRecAttack依然能够有效地毒害推荐模型，展现出其在不同条件下的鲁棒性。

综上所述，我们的工作揭示了联合推荐系统的脆弱性，并证明了FedRecAttack作为一种低成本、高隐秘性的攻击方法能够有效地毒害目标推荐模型。我们的研究还对现有的检测模型中毒攻击和防御模型中毒攻击的方法进行了评估，发现它们在FR中可能不太适用，因为不同用户的特征向量差异较大，导致上传的梯度差异明显。因此，未来有趣的研究方向将包括考虑FR的特殊性，探索更适用于FR的检测和防御模型中毒攻击的方法。通过进一步加强联合推荐系统的安全性，我们可以更好地保护用户的隐私和信息安全。

