## 复现报告

首先在本机上配置Anaconda+PyTorch(GPU版)+CUDA+cuDNN的代码环境,中间尽力经历了一系列版本不匹配和配置失败的问题,最后成功配置,不加赘述

clone项目到本地

阅读论文的代码文件以及readme.md文件,第一次尝试运行代码出现了OMP报错

~~~
OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.
~~~

上网查阅资料发现可能是因为电脑的torch版本太新(2.0.1+cu118),而本项目的运行环境是torch==1.7.0+cu101,根据错误提示在main.py中加入俩行代码后成功运行

~~~python
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
~~~

### 1.基本复现部分

按照论文内容分别在三个不同的数据集进行攻击:

ml-100数据集:

~~~
python main.py --dataset=ml-100k/ --attack=FedRecAttack --clients_limit=0.05 --items_limit=60 --part_percent=1
~~~

![1689793290448](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689793290448.png)

![1689793434224](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689793434224.png)

可以看到看到经过200轮攻击,对于最后一条输出结果解释如下

- 迭代次数：第200次迭代。
- 损失值：损失值为21.82274，表示在该次迭代中模型的训练损失。
- 测试集性能：在测试集上的性能指标为0.5822，表示在Top-K推荐中命中率为0.5822。
- 目标物品性能：性能指标有三项， ER@5和ER@10分别表示在前5，10个推荐结果中，用户实际交互的物品所占的比例。  NDCG@10表示在前10个推荐结果中，用户实际交互的物品的平均排名的归一化值，本次结果在目标物品上的性能指标分别为0.9443、0.9539和0.9448
- 总时间：整个迭代过程的运行时间为1.2秒。

这些性能指标用于评估推荐系统的效果，损失值用于衡量模型的训练效果。根据这些指标的数值，可以判断推荐系统在特定迭代中的性能和训练进展情况。

ml-1m数据集：

~~~
python main.py --dataset=ml-1m/ --attack=FedRecAttack --clients_limit=0.05 --items_limit=60 --part_percent=1
~~~

![1689823831688](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689823831688.png)

![1689824993548](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689824993548.png)

steam数据集：

~~~
python main.py --dataset=steam/ --attack=FedRecAttack --clients_limit=0.05 --items_limit=60 --part_percent=1
~~~

![1689823675684](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689823675684.png)

![1689823746367](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689823746367.png)

可以看到在论文的三个数据集上此攻击方法都运行成功

之后我下载了yelp数据集（Yelp Open Dataset是Yelp业务、评论和用户数据的子集 ），希望测试一下此方法在论文未涉及的数据集的表现。yelp数据集以json格式提供，需要转换成此方法需要的格式

此数据集很大所以运行得非常慢：

~~~
python main.py --dataset=yelp/ --attack=FedRecAttack --clients_limit=0.05 --items_limit=60 --part_percent=1
~~~

![1689837859292](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689837859292.png)

一开始运行良好，直到第38轮可能是攻击太强且数据集过大，模型损坏

与论文中所述数据集越密集攻击越困难这一论述相符合

![1689837887620](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689837887620.png)

### 2.对照试验部分

尝试更换参数重新训练,按照作者思路对于ml-1k数据集进行对照试验

#### （1）设置part percert为不变，改变client_limit（恶意用户比例）分别为0.01，0.02，0.03，0.05，0.10，结果如表所示：

| client limit | 1%     | 2%     | 3%     | 5%     | 10%    |
| ------------ | ------ | ------ | ------ | ------ | ------ |
| ER@5         | 0.0011 | 0.0043 | 0.6602 | 0.9443 | 0.9475 |
| ER@10        | 0.0011 | 0.0075 | 0.717  | 0.9539 | 0.9539 |
| NDCG@10      | 0.0011 | 0.001  | 0.6380 | 0.948  | 0.9424 |

与论文中提供结果基本一致，选取5%为最佳比例![](D:\Users\Administrator\Desktop\大作业3\client.png)

实验截图如下：

0.01：![1689928612958](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928612958.png)![1689928635060](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928635060.png)

0.02![1689881992580](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689881992580.png)![1689882013127](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689882013127.png)

0.03：

![1689928692755](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928692755.png)

![1689928708787](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928708787.png)

0.1     

![1689928819506](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928819506.png)

![1689928833254](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928833254.png)

#### （2）设置client_limit为不变，改变part_percert（公共互动比例）分别为0.01，0.02，0.03，0.05，0.10，结果如表所示：

| part percent | 1%     | 2%     | 3%     | 5%     | 10%    |
| ------------ | ------ | ------ | ------ | ------ | ------ |
| ER@5         | 0.9443 | 0.9786 | 0.9882 | 0.9914 | 0.9807 |
| ER@10        | 0.9539 | 0.9861 | 0.9893 | 0.9946 | 0.9861 |
| NDCG@10      | 0.9448 | 0.9772 | 0.9846 | 0.9887 | 0.9809 |

与论文结果基本一致，取最佳比例为5%![](D:\Users\Administrator\Desktop\大作业3\1.png)

实验截图如下：

2%：

![1689928941234](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928941234.png)

![1689928962318](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689928962318.png)

3%

![1689929021723](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929021723.png)![1689929032527](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929032527.png)

5%

![1689929102221](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929102221.png)

![1689929113640](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929113640.png)

10%

![1689929188689](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929188689.png)![1689929203643](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689929203643.png)

### 3.与其他方法作对比

参数规定:clients_limit = 0.05  part_percent = 1,测试论文提供的攻击方法Random,Bandwagon和Popular与FedRecAttack的性能差异:

| method(clients_limit = 0.05) | FedRecAttack | Random | Bandwagon | Popular |
| ---------------------------- | ------------ | ------ | --------- | ------- |
| ER@5                         | 0.9443       | 0.000  | 0.000     | 0.0011  |
| ER@10                        | 0.9539       | 0.000  | 0.000     | 0.0011  |
| NDCG@10                      | 0.9448       | 0.000  | 0.000     | 0.0011  |

FedRecAttack性能远强于其余三个方法

因为性能指标太小,适当调大恶意用户比例再进行测试,这里调整参数clients_limit = 0.1  part_percent = 1;

| method(clients_limit = 0.1) | FedRecAttack | Random | Bandwagon | Popular |
| --------------------------- | ------------ | ------ | --------- | ------- |
| ER@5                        | 0.9475       | 0.0011 | 0.000     | 0.0032  |
| ER@10                       | 0.9539       | 0.0011 | 0.000     | 0.0075  |
| NDCG@10                     | 0.9424       | 0.005  | 0.000     | 0.0033  |

实验截图如下

Random:0.05

![1689935226936](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935226936.png)

![1689935238497](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935238497.png)

Random:0.1

![1689938575612](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938575612.png)

![1689938593682](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938593682.png)

Bandwagon:0.05

![1689935275452](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935275452.png)

![1689935291840](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935291840.png)

Bandwagon:0.1![1689938657729](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938657729.png)![1689938674148](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938674148.png)

Popular:0.05![1689935311567](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935311567.png)

![1689935322463](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689935322463.png)

Popular:0.1

![1689938975780](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938975780.png)

![1689938957696](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689938957696.png)

### 4.个人方法改进

#### 新方法基本思想:

首先假设攻击者知道每个item的popularity,那么它可以在攻击之前首先构造一个模型,使得target item的embedding为最受欢迎的几个item embedding的平均.为了更好地promote,可以将这个embedding加倍.

然而实际场景下攻击者不知道最受欢迎的item,这可以通过item embedding的l2 norm估计:一般来说,norm越大的item对应的item越受欢迎.

核心代码讲解:

~~~python
import torch
import numpy as np
from parse import args
import torch.nn as nn
import math

class OurAttackClient(nn.Module):
    def __init__(self, target_items):
        super().__init__()
        ...

    def eval_(self, _items_emb):
        # 评估函数，返回 None, None（可以进一步根据需要实现特定的评估功能）

    def compute_k_popularities(self, k, items_emb):
        # 计算基于物品嵌入向量范数的前 k 个最受欢迎的物品
        norms = torch.norm(items_emb, dim=1)
        self.k_popularities = torch.argsort(norms, descending=True)[:k]

    def train_(self, items_emb):
        # 训练攻击模型的函数
        with torch.no_grad():
            if self.global_rounds == args.attack_round:
                # 如果处于攻击轮次，计算 k_popularities 以生成 target_model
                self.compute_k_popularities(args.k, items_emb)
                top_k_embedding = items_emb[self.k_popularities]
                average_top_k_embedding = torch.mean(top_k_embedding, axis=0)
                self.target_model = items_emb.clone()
                # 更新 target_model，将目标物品的嵌入向量更新为 average_top_k_embedding * 10
                self.target_model[self.target_items] = average_top_k_embedding * 10
            
            if self.global_rounds < args.attack_round:
                # 如果不是攻击轮次，返回 None, None, None（可以根据具体条件进一步实现特定的逻辑）
                self.global_rounds += 1
                return None, None, None
            
            self.global_rounds += 1
            # 计算 items_emb_model_update，通过从 target_model 中减去 items_emb，然后乘以 alpha 进行缩放
            items_emb_model_update = (self.target_model - items_emb) * args.alpha
            # 选择要进行模型更新的物品（选择差异范数最大的 args.items_limit - len(self.target_items) 个物品）
            chosen_items = torch.argsort(torch.norm(items_emb_model_update, dim=1), descending=True)[:args.items_limit - len(self.target_items)]
            # 从 chosen_items 中排除目标物品，以避免冗余更新
            chosen_items = torch.tensor(list(set(chosen_items.tolist()) - set(self.target_items))).to(args.device)
            # 将目标物品添加到 chosen_items 以进行更新
            chosen_items = torch.cat((chosen_items, torch.tensor(self.target_items).to(args.device)), dim=0)
        return chosen_items, items_emb_model_update[chosen_items], None

~~~

结果展示:

和论文中的方法进行效果比较,采用的参数是clients_limit=0.03,part_percent=0.1,最终效果如下,新方法优于论文方法.上面是论文方法的结果下面是新方法

![1689956830781](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689956830781.png)

![1689956838484](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689956838484.png)

同时设置前50轮只收集信息,第51轮开始攻击,可以看到结果中的数据在第51轮从零突变到0.98+,并维持在较高水平.(上面是论文方法的结果下面是新方法)

![1689956898167](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689956898167.png)

![1689956906427](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1689956906427.png)